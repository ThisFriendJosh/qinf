---
intrinsic:
  curiosity:
    enabled: true
    beta: 0.2
  compression_gain:
    enabled: true
    beta: 0.1
experiment:
  id: "toy-grid-hq-meta"
  seed: 42
  total_steps: 200000
  log_every: 1000
  eval_every: 10000

env:
  name: "GridWorldToy-v0"
  size: 8
  stochasticity: 0.05
  reward_goal: 1.0
  reward_step: -0.01
  curriculum:
    stages:
      - {size: 6}
      - {size: 8}
      - {size: 10}

model:
  qnet: {type: "dueling", hidden: [256, 256]}
  target_update_interval: 2000
  double_q: true
  distributional: false

hierarchy:
  options:
    - name: "GoToKey"
  scheduler: {type: "epsilon_soft", eps_start: 1.0, eps_end: 0.05, eps_steps: 50000}

intrinsic:
  curiosity: {enabled: true, beta: 0.2}
    - name: "GoToDoor"
    - name: "GoToGoal"
  scheduler: {type: "epsilon_soft", eps_start: 1.0, eps_end: 0.05, eps_steps: 50000}

meta:
  enabled: true
  context_dim: 64
  adapter: {type: "lora", rank: 8}
  update_every: 10000

intrinsic:
  curiosity: {enabled: true, beta: 0.2}
  empowerment: {enabled: false}
  compression_gain: {enabled: true, beta: 0.1}

memory:
  backend: "lmdb"
  path: "./runs/memory"
  ledger_mode: false

optim:
  lr: 0.00025
  batch_size: 128
  gamma: 0.99
  n_step: 3
  replay: {capacity: 200000, warmup: 10000, prioritized: false}
  replay: {capacity: 200000, warmup: 10000, prioritized: true, alpha: 0.6, beta0: 0.4}

eval:
  suites: ["transfer_small_to_large", "option_reuse", "catastrophic_forgetting"]
